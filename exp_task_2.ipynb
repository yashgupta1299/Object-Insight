{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-01T23:03:11.688121Z","iopub.status.busy":"2023-05-01T23:03:11.687564Z","iopub.status.idle":"2023-05-01T23:03:25.434884Z","shell.execute_reply":"2023-05-01T23:03:25.433901Z","shell.execute_reply.started":"2023-05-01T23:03:11.688069Z"},"trusted":true},"outputs":[],"source":["import os\n","# from google.colab import drive\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.utils.vis_utils import plot_model\n","from keras.utils import load_img\n","import numpy as np\n","import pandas as pd\n","from keras.layers import Dense\n","from tensorflow.keras import layers\n","from tensorflow.keras.initializers import glorot_normal\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","# Display\n","# from IPython.display import Image, display\n","import matplotlib.cm as cm\n","from PIL import Image as PILImage"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:25.437446Z","iopub.status.busy":"2023-05-01T23:03:25.436699Z","iopub.status.idle":"2023-05-01T23:03:25.442596Z","shell.execute_reply":"2023-05-01T23:03:25.441436Z","shell.execute_reply.started":"2023-05-01T23:03:25.437408Z"},"trusted":true},"outputs":[],"source":["curr_path = os.getcwd()\n","random_seed =42\n","\n","#Adam Optimiser params\n","lr=1e-3\n","epsilon_val=1e-8\n","beta1=0.9\n","beta2=0.999"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:25.444481Z","iopub.status.busy":"2023-05-01T23:03:25.443923Z","iopub.status.idle":"2023-05-01T23:03:25.464795Z","shell.execute_reply":"2023-05-01T23:03:25.463698Z","shell.execute_reply.started":"2023-05-01T23:03:25.444449Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/output-layer-vgg19'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path_in \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/kaggle/input/assn-5-load/Group_20\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m path_model \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/kaggle/input/output-layer-vgg19\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(path_model))\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/output-layer-vgg19'"]}],"source":["path_in = '/kaggle/input/assn-5-load/Group_20'\n","path_model = '/kaggle/input/output-layer-vgg19'\n","print(os.listdir(path_model))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:25.467673Z","iopub.status.busy":"2023-05-01T23:03:25.467359Z","iopub.status.idle":"2023-05-01T23:03:29.887610Z","shell.execute_reply":"2023-05-01T23:03:29.886597Z","shell.execute_reply.started":"2023-05-01T23:03:25.467643Z"},"trusted":true},"outputs":[],"source":["if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")"]},{"cell_type":"markdown","metadata":{},"source":["## Read Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:29.891728Z","iopub.status.busy":"2023-05-01T23:03:29.890216Z","iopub.status.idle":"2023-05-01T23:03:30.485270Z","shell.execute_reply":"2023-05-01T23:03:30.484401Z","shell.execute_reply.started":"2023-05-01T23:03:29.891688Z"},"trusted":true},"outputs":[],"source":["class_names = ['brain', 'butterfly', 'ewer', 'helicopter', 'ketch']\n","normalization_layer = tf.keras.layers.Rescaling(1./255)\n","\n","## read training data\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    path_in + '/train/',\n","    batch_size=32,\n","    seed = random_seed,\n","    image_size=(224, 224)\n",").map(lambda x, y: (normalization_layer(x), y))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:30.487200Z","iopub.status.busy":"2023-05-01T23:03:30.486858Z","iopub.status.idle":"2023-05-01T23:03:30.551129Z","shell.execute_reply":"2023-05-01T23:03:30.550114Z","shell.execute_reply.started":"2023-05-01T23:03:30.487167Z"},"trusted":true},"outputs":[],"source":["# load validation dataset \n","valid_ds = tf.keras.utils.image_dataset_from_directory(\n","    path_in + '/val/',\n","    batch_size=32,\n","    seed = random_seed,\n","    image_size=(224, 224),\n","    shuffle=False\n",").map(lambda x, y: (normalization_layer(x), y))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:30.552988Z","iopub.status.busy":"2023-05-01T23:03:30.552665Z","iopub.status.idle":"2023-05-01T23:03:30.644187Z","shell.execute_reply":"2023-05-01T23:03:30.642937Z","shell.execute_reply.started":"2023-05-01T23:03:30.552956Z"},"trusted":true},"outputs":[],"source":["# load test dataset \n","test_ds = tf.keras.utils.image_dataset_from_directory(\n","    path_in + '/test/',\n","    batch_size=32,\n","    seed = random_seed,\n","    image_size=(224, 224)\n",").map(lambda x, y: (normalization_layer(x), y))"]},{"cell_type":"markdown","metadata":{},"source":["### Visualise some of the validation images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:30.645898Z","iopub.status.busy":"2023-05-01T23:03:30.645587Z","iopub.status.idle":"2023-05-01T23:03:32.336974Z","shell.execute_reply":"2023-05-01T23:03:32.336166Z","shell.execute_reply.started":"2023-05-01T23:03:30.645867Z"},"trusted":true},"outputs":[],"source":["image_super = [] # pairs of images and corresponding labels (will be used for plotting and other experiments)\n","plt.figure(figsize=(10, 10))\n","for i in range(5):\n","    label_idx = i%5\n","    for batch_images, batch_labels in valid_ds:\n","        mask = (batch_labels == label_idx)\n","        if tf.reduce_any(mask): #checks if any value in mask tensor is true\n","            indices = tf.argmax(mask)\n","            ax = plt.subplot(3, 3, i + 1)\n","            plt.imshow((batch_images[indices].numpy()*255).astype(\"uint8\"))\n","            plt.title(class_names[batch_labels[indices]])\n","            plt.axis(\"off\")\n","            image_super.append([batch_images[indices], batch_labels[indices]])\n","            break  \n"]},{"cell_type":"markdown","metadata":{},"source":["## Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:32.338313Z","iopub.status.busy":"2023-05-01T23:03:32.337942Z","iopub.status.idle":"2023-05-01T23:03:32.348638Z","shell.execute_reply":"2023-05-01T23:03:32.347637Z","shell.execute_reply.started":"2023-05-01T23:03:32.338276Z"},"trusted":true},"outputs":[],"source":["# Define the layers whose weights you want to save\n","layer_names = ['output_layer']\n","\n","# Define the custom callback function to save the weights of specific layers\n","class SaveLayerWeightsCallback(ModelCheckpoint):\n","    def __init__(self, filepath, layers, **kwargs):\n","        self.layers = layers\n","        self.filepath = filepath\n","        super().__init__(filepath, **kwargs)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        for layer_name in self.layers:\n","            layer = self.model.get_layer(layer_name)\n","            weights = layer.get_weights()\n","            if not os.path.exists(self.filepath):\n","              os.mkdir(self.filepath)\n","            filename1 = f\"{layer_name}_epoch_{epoch}_weights.csv\"\n","            filename2 = f\"{layer_name}_epoch_{epoch}_bias.csv\"\n","            filepath1 = os.path.join(self.filepath, filename1)\n","            filepath2 = os.path.join(self.filepath, filename2)\n","            # layer.save_weights(filepath)\n","            pd.DataFrame(weights[0]).to_csv(filepath1, index=False)\n","            pd.DataFrame(np.array([weights[1]])).to_csv(filepath2, index=False)\n","            # pd.DataFrame(weights).to_csv(filepath) # this saves array as a string and which is problamatic\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:32.355084Z","iopub.status.busy":"2023-05-01T23:03:32.354587Z","iopub.status.idle":"2023-05-01T23:03:32.360780Z","shell.execute_reply":"2023-05-01T23:03:32.359875Z","shell.execute_reply.started":"2023-05-01T23:03:32.355052Z"},"trusted":true},"outputs":[],"source":["threshold_val = 0.0001\n","early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                  patience=3,\n","                                                  min_delta=threshold_val,\n","                                                  mode='min',\n","                                                  restore_best_weights=True, \n","                                                  verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:32.363331Z","iopub.status.busy":"2023-05-01T23:03:32.362173Z","iopub.status.idle":"2023-05-01T23:03:32.375987Z","shell.execute_reply":"2023-05-01T23:03:32.375036Z","shell.execute_reply.started":"2023-05-01T23:03:32.363300Z"},"trusted":true},"outputs":[],"source":["# Create an instance of the custom callback\n","save_layer_weights = SaveLayerWeightsCallback(filepath='sequential-model-weights/', layers=layer_names)"]},{"cell_type":"markdown","metadata":{},"source":["## Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:32.377528Z","iopub.status.busy":"2023-05-01T23:03:32.377145Z","iopub.status.idle":"2023-05-01T23:03:39.034171Z","shell.execute_reply":"2023-05-01T23:03:39.033227Z","shell.execute_reply.started":"2023-05-01T23:03:32.377497Z"},"trusted":true},"outputs":[],"source":["vgg19 = tf.keras.applications.VGG19(\n","    include_top=True,\n","    weights=\"imagenet\",\n","    classes=1000,\n","    classifier_activation=\"softmax\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:39.035764Z","iopub.status.busy":"2023-05-01T23:03:39.035434Z","iopub.status.idle":"2023-05-01T23:03:40.353219Z","shell.execute_reply":"2023-05-01T23:03:40.352163Z","shell.execute_reply.started":"2023-05-01T23:03:39.035731Z"},"trusted":true},"outputs":[],"source":["inp = tf.keras.layers.Input(shape=(224, 224, 3))\n","base_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_tensor=inp,\n","                                          input_shape=(224, 224, 3))"]},{"cell_type":"markdown","metadata":{},"source":["## Load weights and bias for best results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:40.359356Z","iopub.status.busy":"2023-05-01T23:03:40.356942Z","iopub.status.idle":"2023-05-01T23:03:40.415149Z","shell.execute_reply":"2023-05-01T23:03:40.414343Z","shell.execute_reply.started":"2023-05-01T23:03:40.359320Z"},"trusted":true},"outputs":[],"source":["print(path_model)\n","best_w = pd.read_csv(path_model + '/output_layer_epoch_2_weights.csv', dtype='float32').values\n","best_b = pd.read_csv(path_model + '/output_layer_epoch_2_bias.csv', dtype='float32').values[0]"]},{"cell_type":"markdown","metadata":{},"source":["## Complete Transfer Learning Model Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:40.420938Z","iopub.status.busy":"2023-05-01T23:03:40.418883Z","iopub.status.idle":"2023-05-01T23:03:40.884359Z","shell.execute_reply":"2023-05-01T23:03:40.883352Z","shell.execute_reply.started":"2023-05-01T23:03:40.420904Z"},"trusted":true},"outputs":[],"source":["Flatten = tf.keras.layers.Flatten(name=\"flatten\") # flatten output of last convolution layer\n","fc1 = tf.keras.layers.Dense(4096, activation='relu', name='fc1')\n","fc2 = tf.keras.layers.Dense(4096, activation='relu', name = 'fc2')\n","prediction = tf.keras.layers.Dense(5, activation='softmax', name='output')\n","\n","imsize = [224, 224, 3]\n","inp = layers.Input(shape=(imsize[0], imsize[1], imsize[2]))\n","base_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_tensor=inp,\n","                                          input_shape=(imsize[0], imsize[1], imsize[2]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:40.891382Z","iopub.status.busy":"2023-05-01T23:03:40.888862Z","iopub.status.idle":"2023-05-01T23:03:40.941561Z","shell.execute_reply":"2023-05-01T23:03:40.940773Z","shell.execute_reply.started":"2023-05-01T23:03:40.891344Z"},"trusted":true},"outputs":[],"source":["## Creating transfer learning model using functional API\n","block5_pool = base_model.get_layer('block5_pool')\n","x = Flatten(block5_pool.output)\n","x = fc1(x)\n","x = fc2(x)\n","x = prediction(x)\n","model = tf.keras.models.Model(inputs = inp, outputs = x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:40.947636Z","iopub.status.busy":"2023-05-01T23:03:40.945551Z","iopub.status.idle":"2023-05-01T23:03:40.971757Z","shell.execute_reply":"2023-05-01T23:03:40.970985Z","shell.execute_reply.started":"2023-05-01T23:03:40.947603Z"},"trusted":true},"outputs":[],"source":["model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n","                       optimizer=keras.optimizers.Adam(learning_rate=lr,\n","                                                       epsilon=epsilon_val,\n","                                                       beta_1=beta1,\n","                                                       beta_2=beta2),\n","                        metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:40.977543Z","iopub.status.busy":"2023-05-01T23:03:40.975577Z","iopub.status.idle":"2023-05-01T23:03:40.984012Z","shell.execute_reply":"2023-05-01T23:03:40.983244Z","shell.execute_reply.started":"2023-05-01T23:03:40.977511Z"},"trusted":true},"outputs":[],"source":["# freeze all the convolution layers in training\n","for hl in model.layers:\n","    hl.trainable = False\n","model.get_layer('output').trainable = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:40.990258Z","iopub.status.busy":"2023-05-01T23:03:40.987930Z","iopub.status.idle":"2023-05-01T23:03:42.089705Z","shell.execute_reply":"2023-05-01T23:03:42.088745Z","shell.execute_reply.started":"2023-05-01T23:03:40.990227Z"},"trusted":true},"outputs":[],"source":["## Change weights of last fully connected layer to have \n","## weights from best model weights from earlier training\n","model.get_layer('fc1').set_weights(vgg19.get_layer('fc1').get_weights())\n","model.get_layer('fc2').set_weights(vgg19.get_layer('fc2').get_weights())\n","model.get_layer('output').set_weights([best_w, best_b])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:42.091522Z","iopub.status.busy":"2023-05-01T23:03:42.091146Z","iopub.status.idle":"2023-05-01T23:03:42.137090Z","shell.execute_reply":"2023-05-01T23:03:42.136408Z","shell.execute_reply.started":"2023-05-01T23:03:42.091467Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Prediction using Model and Confusion Matrix\n","-  best model weights is achieved in epoch 3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:03:42.138346Z","iopub.status.busy":"2023-05-01T23:03:42.138011Z","iopub.status.idle":"2023-05-01T23:04:03.152830Z","shell.execute_reply":"2023-05-01T23:04:03.151012Z","shell.execute_reply.started":"2023-05-01T23:03:42.138313Z"},"trusted":true},"outputs":[],"source":["test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n","print(\"test accuracy = \", test_acc)\n","print(\"test loss \", test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:04:03.155625Z","iopub.status.busy":"2023-05-01T23:04:03.155227Z","iopub.status.idle":"2023-05-01T23:04:17.477382Z","shell.execute_reply":"2023-05-01T23:04:17.476279Z","shell.execute_reply.started":"2023-05-01T23:04:03.155591Z"},"trusted":true},"outputs":[],"source":["_, train_acc = model.evaluate(train_ds, verbose=0)\n","_, val_acc = model.evaluate(valid_ds, verbose=0)\n","print(f\"training accuracy = {train_acc :.3f}\")\n","print(f\"validation accuracy = {val_acc :.3f}\" )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:04:17.479185Z","iopub.status.busy":"2023-05-01T23:04:17.478844Z","iopub.status.idle":"2023-05-01T23:04:17.489040Z","shell.execute_reply":"2023-05-01T23:04:17.488068Z","shell.execute_reply.started":"2023-05-01T23:04:17.479154Z"},"trusted":true},"outputs":[],"source":["def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=10): \n","  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n","\n","  If classes is passed, confusion matrix will be labelled, if not, integer class values\n","  will be used.\n","\n","  Args:\n","    y_true: Array of truth labels (must be same shape as y_pred).\n","    y_pred: Array of predicted labels (must be same shape as y_true).\n","    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n","    figsize: Size of output figure (default=(10, 10)).\n","    text_size: Size of output figure text (default=15).\n","  \n","  Returns:\n","    A labelled confusion matrix plot comparing y_true and y_pred.\n","  \"\"\"  \n","  # Create the confustion matrix\n","  cm = confusion_matrix(y_true, y_pred)\n","  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n","  n_classes = cm.shape[0] # find the number of classes we're dealing with\n","\n","  # overall accuracy\n","  true_cls = 0\n","  for i in range(cm.shape[0]):\n","    true_cls += cm[i][i]\n","  acc_all = (true_cls/len(y_true))*100\n","\n","  # Plot the figure and make it pretty\n","  fig, ax = plt.subplots(figsize=figsize)\n","  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n","  # fig.colorbar(cax) # for now skip plotting heat index\n","\n","  # Are there a list of classes?\n","  if classes:\n","    labels = classes\n","  else:\n","    labels = np.arange(cm.shape[0])\n","  \n","  # Label the axes \n","  ax.set(title=f\"Confusion Matrix\\naccuracy: {acc_all}\",\n","         xlabel=\"Predicted label\",\n","         ylabel=\"True label\",\n","         xticks=np.arange(n_classes), # create enough axis slots for each class\n","         yticks=np.arange(n_classes), \n","         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n","         yticklabels=labels)\n","\n","  # Make x-axis labels appear on bottom\n","  ax.xaxis.set_label_position(\"bottom\")\n","  ax.xaxis.tick_bottom()\n","\n","  # Set the threshold for different colors\n","  threshold = (cm.max() + cm.min()) / 2.\n","\n","  # Plot the text on each cell\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n","             horizontalalignment=\"center\",\n","             color=\"white\" if cm[i, j] > threshold else \"black\",\n","             size=text_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:04:17.490997Z","iopub.status.busy":"2023-05-01T23:04:17.490433Z","iopub.status.idle":"2023-05-01T23:04:17.532225Z","shell.execute_reply":"2023-05-01T23:04:17.531401Z","shell.execute_reply.started":"2023-05-01T23:04:17.490963Z"},"trusted":true},"outputs":[],"source":["def plot_confusion_matrix(data_set, label_names):\n","  # Get true labels\n","  true_labels = []\n","  predicted_ =[]\n","  for images, labels in data_set:\n","    true_labels += labels.numpy().tolist()\n","    predicted_ += model.predict(images, verbose=0).argmax(axis=1).tolist()\n","  make_confusion_matrix(true_labels, predicted_, label_names)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:04:17.535571Z","iopub.status.busy":"2023-05-01T23:04:17.535306Z","iopub.status.idle":"2023-05-01T23:04:20.644851Z","shell.execute_reply":"2023-05-01T23:04:20.643975Z","shell.execute_reply.started":"2023-05-01T23:04:17.535547Z"},"trusted":true},"outputs":[],"source":["print('                    |------------------- confusion matrix for training datasets --------------|')\n","print()\n","plot_confusion_matrix(train_ds, class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:04:20.647432Z","iopub.status.busy":"2023-05-01T23:04:20.646444Z","iopub.status.idle":"2023-05-01T23:04:21.654893Z","shell.execute_reply":"2023-05-01T23:04:21.654003Z","shell.execute_reply.started":"2023-05-01T23:04:20.647397Z"},"trusted":true},"outputs":[],"source":["print('                    |------------------- confusion matrix for validation datasets --------------|')\n","print()\n","plot_confusion_matrix(valid_ds, class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:04:21.657450Z","iopub.status.busy":"2023-05-01T23:04:21.656722Z","iopub.status.idle":"2023-05-01T23:04:23.288883Z","shell.execute_reply":"2023-05-01T23:04:23.288003Z","shell.execute_reply.started":"2023-05-01T23:04:21.657413Z"},"trusted":true},"outputs":[],"source":["print('                    |------------------- confusion matrix for test datasets --------------|')\n","print()\n","plot_confusion_matrix(test_ds, class_names)"]},{"cell_type":"markdown","metadata":{},"source":["## Receptive Field Calculation\n","- Tracing back to the patch in the image which causes convolution neurons to fire"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:04:23.295440Z","iopub.status.busy":"2023-05-01T23:04:23.294803Z","iopub.status.idle":"2023-05-01T23:04:23.305018Z","shell.execute_reply":"2023-05-01T23:04:23.304151Z","shell.execute_reply.started":"2023-05-01T23:04:23.295401Z"},"trusted":true},"outputs":[],"source":["last_conv_layer_name, last_conv_layer_idx = \"block5_conv4\", 20\n","\n","## create a submodel to calculate output of last convolution layer\n","receptive_model_calc = tf.keras.Model(\n","    inputs = model.input,\n","    outputs = model.get_layer(last_conv_layer_name).output)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:04:23.306931Z","iopub.status.busy":"2023-05-01T23:04:23.306551Z","iopub.status.idle":"2023-05-01T23:04:23.313615Z","shell.execute_reply":"2023-05-01T23:04:23.312692Z","shell.execute_reply.started":"2023-05-01T23:04:23.306895Z"},"trusted":true},"outputs":[],"source":["# function to calculate argmax of a tensor or 3D matrix\n","def findArgmax(arr):\n","    flattend_argmax = np.argmax(arr)\n","    req_argmax = np.unravel_index(flattend_argmax, arr.shape)\n","    return req_argmax[1:-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:21.330791Z","iopub.status.busy":"2023-05-01T23:07:21.330340Z","iopub.status.idle":"2023-05-01T23:07:21.343175Z","shell.execute_reply":"2023-05-01T23:07:21.340573Z","shell.execute_reply.started":"2023-05-01T23:07:21.330750Z"},"trusted":true},"outputs":[],"source":["def trace_ipnput_patch(left, right, hidd_layer, model):\n","    top_left = left\n","    bottom_right = right\n","    \n","    # trace From last layer to input layer\n","    for i in range(hidd_layer, 0, -1): \n","        curr_layer = model.layers[i] \n","        if isinstance(model.layers[i], tf.keras.layers.Conv2D):\n","            kernel_sz = curr_layer.kernel_size[0]\n","        else:\n","            kernel_sz = curr_layer.pool_size[0]\n","            \n","        s = curr_layer.strides[0]\n","        l_i, l_j = top_left\n","        r_i, r_j = bottom_right\n","        \n","        ## difficult case need to take care of padding (think backward)\n","        if curr_layer.padding == 'same':\n","            p = int(kernel_sz/2)\n","            l_ix = max(0, s * l_i - p)\n","            l_iy = max(0, s * l_j - p)\n","            r_ix = min(s * r_i + (kernel_sz-1) - p, curr_layer.output.shape[1])\n","            r_iy = min(s * r_j + (kernel_sz-1) - p, curr_layer.output.shape[2])\n","            top_left = l_ix, l_iy\n","            bottom_right = r_ix, r_iy\n","            \n","        else:\n","            top_left = s * l_i, s * l_j\n","            bottom_right = s * r_i + (kernel_sz-1), s * r_j + (kernel_sz-1)\n","    \n","    return top_left, bottom_right"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:21.638635Z","iopub.status.busy":"2023-05-01T23:07:21.637963Z","iopub.status.idle":"2023-05-01T23:07:21.643626Z","shell.execute_reply":"2023-05-01T23:07:21.642511Z","shell.execute_reply.started":"2023-05-01T23:07:21.638599Z"},"trusted":true},"outputs":[],"source":["def norm_flat_image(img):\n","    grads_norm = img #[:,:,0]+ img[:,:,1]+ img[:,:,2]\n","    grads_norm = (grads_norm - tf.reduce_min(grads_norm))/ (tf.reduce_max(grads_norm)- tf.reduce_min(grads_norm))\n","    return grads_norm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:22.001676Z","iopub.status.busy":"2023-05-01T23:07:22.001096Z","iopub.status.idle":"2023-05-01T23:07:23.920772Z","shell.execute_reply":"2023-05-01T23:07:23.920021Z","shell.execute_reply.started":"2023-05-01T23:07:22.001633Z"},"trusted":true},"outputs":[],"source":["\n","plt.figure(figsize=(10, 10))\n","count = 0\n","for image_ in image_super:  \n","    img1 = image_[0]*255 \n","    output = receptive_model_calc.predict(np.array([img1]), verbose=0)\n","    maximal_neuron = findArgmax(output)\n","    left_idx, right_idx = trace_ipnput_patch(maximal_neuron, maximal_neuron, last_conv_layer_idx, receptive_model_calc)\n","\n","    cropped_img = img1.numpy().copy()\n","    for i in range(img1.shape[0]):\n","        for j in range(img1.shape[1]):\n","            l_i, l_j = left_idx\n","            r_i, r_j = right_idx\n","            if(i < l_i or j < l_j or i > r_i or j > r_j):\n","                cropped_img[i,j,:] //=2\n","            elif(i in [l_i, l_i-1, l_i+1] or i in [r_i, r_i-1, r_i+1] or j in [l_j, l_j-1, l_j+1] or j in [r_j, r_j-1, r_j+1]):\n","                cropped_img[i,j,0] = 208\n","                cropped_img[i,j,1] = 89\n","                cropped_img[i,j,2] = 198\n","    ax = plt.subplot(3, 4, count + 1)\n","    plt.imshow(norm_flat_image(img1))\n","    plt.title(f'Normal image\\n{class_names[image_[1]]}', fontsize=10)\n","    plt.axis('off')\n","    ax = plt.subplot(3, 4, count + 2)\n","    plt.imshow(norm_flat_image(cropped_img))\n","    plt.title('cropped image')\n","    plt.axis('off')\n","    count += 2"]},{"cell_type":"markdown","metadata":{},"source":["## Guided-backpropagation algorithm\n","---\n","#### To calculate the influence of input images on output of a neuron in convolution layer\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:28.749499Z","iopub.status.busy":"2023-05-01T23:07:28.749152Z","iopub.status.idle":"2023-05-01T23:07:28.757123Z","shell.execute_reply":"2023-05-01T23:07:28.756147Z","shell.execute_reply.started":"2023-05-01T23:07:28.749470Z"},"trusted":true},"outputs":[],"source":["@tf.custom_gradient\n","def guidedRelu(x):\n","    # upstream is gradient flowing from next layer in backpropagation\n","    def grad(upstream):\n","        return tf.cast(upstream>0,tf.float32)  * tf.cast(x>0,tf.float32) * upstream\n","    return tf.nn.relu(x), grad"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:29.648927Z","iopub.status.busy":"2023-05-01T23:07:29.647883Z","iopub.status.idle":"2023-05-01T23:07:29.656246Z","shell.execute_reply":"2023-05-01T23:07:29.655088Z","shell.execute_reply.started":"2023-05-01T23:07:29.648887Z"},"trusted":true},"outputs":[],"source":["## change all the relu activations to guidedRelu \n","## this will facilitate only positive gradients to flow during backpropagation\n","def changeActivation(model, isGuidedRelu=True):\n","    \n","    if(isGuidedRelu == True):\n","        for hidden_layers in model.layers:\n","            if hasattr(hidden_layers, 'activation'):\n","                if hidden_layers.activation == tf.keras.activations.relu:\n","                    hidden_layers.activation = guidedRelu\n","                    print(hidden_layers.name, \" --> activation changed to guidedRelu\")\n","    else: # change back to normal\n","        for hidden_layers in model.layers:\n","            if hasattr(hidden_layers, 'activation'):\n","                if hidden_layers.activation:\n","                    hidden_layers.activation = tf.keras.activations.relu\n","                    print(hidden_layers.name, \" --> activation changed to relu\")\n","    model.get_layer('output').activation = None #tf.keras.activations.softmax\n","    print(hidden_layers.name, \" --> activation changed to softmax\")       \n","    return\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:14:19.467955Z","iopub.status.busy":"2023-05-01T23:14:19.467198Z","iopub.status.idle":"2023-05-01T23:14:19.476062Z","shell.execute_reply":"2023-05-01T23:14:19.475085Z","shell.execute_reply.started":"2023-05-01T23:14:19.467921Z"},"trusted":true},"outputs":[],"source":["changeActivation(model, isGuidedRelu=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:14:21.666750Z","iopub.status.busy":"2023-05-01T23:14:21.666000Z","iopub.status.idle":"2023-05-01T23:14:21.706148Z","shell.execute_reply":"2023-05-01T23:14:21.705439Z","shell.execute_reply.started":"2023-05-01T23:14:21.666712Z"},"trusted":true},"outputs":[],"source":["## we'll make use of above defined model\n","print(\"Model :summary guided backpropagation\")\n","print(receptive_model_calc.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:14:22.272854Z","iopub.status.busy":"2023-05-01T23:14:22.272029Z","iopub.status.idle":"2023-05-01T23:14:22.281051Z","shell.execute_reply":"2023-05-01T23:14:22.279870Z","shell.execute_reply.started":"2023-05-01T23:14:22.272817Z"},"trusted":true},"outputs":[],"source":["def guidedBP_input_influence(img, target_neuron_idx = 0):\n","    # output_conv = receptive_model_calc.predict(np.array([img]), verbose=0)\n","     # position of neuron : target_neuron_idx \n","    \n","    with tf.GradientTape() as tape:\n","        tape.watch(img)\n","        target_activations = receptive_model_calc(tf.expand_dims(img, axis=0))[:, :, :, target_neuron_idx]\n","    grads1 = tape.gradient(target_activations, img)\n","    \n","    inp_img1 = tf.expand_dims(img, axis=0)\n","    with tf.GradientTape() as tape:\n","        tape.watch(inp_img1)\n","        preds = model(inp_img1)\n","        pred_idx = tf.argmax(preds, axis=1)\n","        pred_val = preds[0,pred_idx[0]]\n","    grads2 = tape.gradient(pred_val, inp_img1)\n","    \n","    return {'grads_conv': grads1, 'grads_op': grads2 ,'neuron_pos': target_neuron_idx}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:14:23.414489Z","iopub.status.busy":"2023-05-01T23:14:23.414149Z","iopub.status.idle":"2023-05-01T23:14:25.643784Z","shell.execute_reply":"2023-05-01T23:14:25.643008Z","shell.execute_reply.started":"2023-05-01T23:14:23.414459Z"},"trusted":true},"outputs":[],"source":["\n","plt.figure(figsize=(10, 10))\n","count = 0\n","for image_ in image_super:  \n","    img1 = image_[0]*255 \n","    grads = guidedBP_input_influence(img1)\n","    ax = plt.subplot(5, 3, count + 1)\n","    plt.imshow(norm_flat_image(img1))\n","    plt.title(f'Original image\\n{class_names[image_[1]]}', fontsize=10)\n","    plt.axis('off')\n","    ax = plt.subplot(5, 3, count + 2)\n","    plt.imshow(norm_flat_image(grads['grads_op'][0]))\n","    plt.title('guided-backprop\\n output', fontsize=10)\n","    plt.axis('off')\n","    ax = plt.subplot(5, 3, count + 3)\n","    plt.imshow(norm_flat_image(grads['grads_conv']))\n","    plt.title('guided-backprop\\nfrom conv_neuron', fontsize=10)\n","    plt.axis('off')\n","    count += 3\n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["## Grad-CAM class activation visualization\n","--- \n","### [stackoverflow refrence link](https://stackoverflow.com/questions/60623869/gradcam-with-guided-backprop-for-transfer-learning-in-tensorflow-2-0)\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:36.293122Z","iopub.status.busy":"2023-05-01T23:07:36.292464Z","iopub.status.idle":"2023-05-01T23:07:36.296929Z","shell.execute_reply":"2023-05-01T23:07:36.296230Z","shell.execute_reply.started":"2023-05-01T23:07:36.293069Z"},"trusted":true},"outputs":[],"source":["last_conv_layer_name = \"block5_conv4\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:36.299044Z","iopub.status.busy":"2023-05-01T23:07:36.298433Z","iopub.status.idle":"2023-05-01T23:07:36.312191Z","shell.execute_reply":"2023-05-01T23:07:36.311172Z","shell.execute_reply.started":"2023-05-01T23:07:36.299014Z"},"trusted":true},"outputs":[],"source":["def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    # First, we create a model that maps the input image to the activations\n","    # of the last conv layer as well as the output predictions\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    # This is the gradient of the output neuron (top predicted or chosen)\n","    # with regard to the output feature map of the last conv layer\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    # then sum all the channels to obtain the heatmap class activation\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:36.394893Z","iopub.status.busy":"2023-05-01T23:07:36.394638Z","iopub.status.idle":"2023-05-01T23:07:36.403453Z","shell.execute_reply":"2023-05-01T23:07:36.402435Z","shell.execute_reply.started":"2023-05-01T23:07:36.394870Z"},"trusted":true},"outputs":[],"source":["def save_and_display_gradcam(img, heatmap, cam_path = 'cam.jpg', alpha=0.4):\n","    # Load the original image\n","#     img = keras.preprocessing.image.load_img(img_path)\n","#     img = keras.preprocessing.image.img_to_array(img)\n","\n","    # Rescale heatmap to a range 0-255\n","    heatmap = np.uint8(255 * heatmap)\n","\n","    # Use jet colormap to colorize heatmap\n","    jet = cm.get_cmap(\"jet\")\n","\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","\n","    # Create an image with RGB colorized heatmap\n","    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n","\n","    # Superimpose the heatmap on original image\n","    superimposed_img = jet_heatmap * alpha + img\n","    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n","\n","#     # Save the superimposed image\n","#     superimposed_img.save(cam_path)\n","\n","#     # Display Grad CAM\n","#     display(Image(cam_path))\n","    img = keras.preprocessing.image.img_to_array(superimposed_img)/255.0\n","    return img\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:36.943245Z","iopub.status.busy":"2023-05-01T23:07:36.942073Z","iopub.status.idle":"2023-05-01T23:07:36.952675Z","shell.execute_reply":"2023-05-01T23:07:36.951415Z","shell.execute_reply.started":"2023-05-01T23:07:36.943151Z"},"trusted":true},"outputs":[],"source":["def compute_all_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    if model.layers[-1].activation != None:\n","        model.layers[-1].activation = None\n","    \n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","    \n","    with tf.GradientTape(persistent=True) as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        num_class = preds.shape[1]\n","        # if pred_index is None:\n","        #     pred_index = tf.argmax(preds[0])\n","        class_channels = [preds[:, i] for i in range(num_class)]\n","    \n","    \n","    grads_all = [tape.gradient(class_channels[i], last_conv_layer_output) for i in range(num_class)]\n","\n","    pooled_grads_all = [tf.reduce_mean(grads_all[i], axis=(0, 1, 2)) for i in range(num_class)]\n","    \n","    heatmap_all = []\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    for i in range(num_class):\n","        heatmap = last_conv_layer_output @ pooled_grads_all[i][..., tf.newaxis]\n","        heatmap = tf.squeeze(heatmap)\n","        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","        heatmap_all.append(heatmap)\n","    \n","    # return heatmap of all classes along with class_index of predicted class as a dict\n","    grad_cams = {'heatmaps': heatmap_all, 'pred_idx': pred_index}\n","    return grad_cams"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:33:02.783871Z","iopub.status.busy":"2023-05-01T23:33:02.783482Z","iopub.status.idle":"2023-05-01T23:33:02.791624Z","shell.execute_reply":"2023-05-01T23:33:02.790540Z","shell.execute_reply.started":"2023-05-01T23:33:02.783841Z"},"trusted":true},"outputs":[],"source":["changeActivation(model, isGuidedRelu=False) # undo the previous action first"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:37.241867Z","iopub.status.busy":"2023-05-01T23:07:37.239730Z","iopub.status.idle":"2023-05-01T23:07:37.321312Z","shell.execute_reply":"2023-05-01T23:07:37.320315Z","shell.execute_reply.started":"2023-05-01T23:07:37.241835Z"},"trusted":true},"outputs":[],"source":["array = image_super[2][0].numpy()\n","img_array = np.expand_dims(array, axis=0)\n","preds = model.predict(img_array, verbose=0 )\n","print(\"Predicted:\", class_names[preds.argmax(axis=1)[0]])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:37.905535Z","iopub.status.busy":"2023-05-01T23:07:37.905187Z","iopub.status.idle":"2023-05-01T23:07:38.302195Z","shell.execute_reply":"2023-05-01T23:07:38.301254Z","shell.execute_reply.started":"2023-05-01T23:07:37.905505Z"},"trusted":true},"outputs":[],"source":["array = image_super[2][0].numpy()\n","img_array = np.expand_dims(array, axis=0)\n","heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n","img = save_and_display_gradcam(array*255, heatmap)\n","plt.imshow(img)\n","plt.title('GradCAM visualization', fontsize=10)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:38.845931Z","iopub.status.busy":"2023-05-01T23:07:38.845572Z","iopub.status.idle":"2023-05-01T23:07:39.236819Z","shell.execute_reply":"2023-05-01T23:07:39.235907Z","shell.execute_reply.started":"2023-05-01T23:07:38.845901Z"},"trusted":true},"outputs":[],"source":["array = image_super[4][0].numpy()\n","img_array = np.expand_dims(array, axis=0)\n","heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n","img = save_and_display_gradcam(array*255, heatmap)\n","plt.imshow(img)\n","plt.title('GradCAM visualization', fontsize=10)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:39.728125Z","iopub.status.busy":"2023-05-01T23:07:39.727779Z","iopub.status.idle":"2023-05-01T23:07:39.735423Z","shell.execute_reply":"2023-05-01T23:07:39.734442Z","shell.execute_reply.started":"2023-05-01T23:07:39.728079Z"},"trusted":true},"outputs":[],"source":["def visualise_heat_map_all(img_, model=model, last_conv_layer_name = \"block5_conv4\"):\n","    array = img_.numpy()\n","    img_array = np.expand_dims(array, axis=0)\n","    cal_gradcams = compute_all_gradcam_heatmap(img_array, model, last_conv_layer_name)\n","    plt.figure(figsize=(10, 10))\n","    for i, heatmap in enumerate(cal_gradcams.get('heatmaps')):\n","        ax = plt.subplot(3, 3, i + 1)\n","        img = save_and_display_gradcam(array*255, heatmap)\n","        plt.imshow(img)\n","        title = \"\"\n","        if i == cal_gradcams.get('pred_idx'):\n","            title = f'with respect to actual\\npredicted class: {class_names[i]}'\n","        else:\n","            title = f'with respect to\\nclass: {class_names[i]}'\n","        plt.title(title, fontsize=10)\n","        plt.axis(\"off\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T23:07:40.849492Z","iopub.status.busy":"2023-05-01T23:07:40.849147Z","iopub.status.idle":"2023-05-01T23:07:44.856927Z","shell.execute_reply":"2023-05-01T23:07:44.856166Z","shell.execute_reply.started":"2023-05-01T23:07:40.849466Z"},"trusted":true},"outputs":[],"source":["for i in range(5):\n","    visualise_heat_map_all(image_super[i][0], model)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
